\documentclass[10pt, compress]{beamer}
\XeTeXlinebreaklocale "ja"
\XeTeXlinebreakskip=0em plus 0.1em minus 0.01em

\usetheme[usetitleprogressbar]{m}

\usepackage{booktabs}
\usepackage{minted}
\usepackage{fontawesome}
\usepackage{gnuplot-lua-tikz}
\usepackage{tcolorbox}

%%% user macro
\definecolor{links}{HTML}{DB4D6D} % NAKABENI
\hypersetup{colorlinks,linkcolor=,urlcolor=links}

%\tcbset{
%	width=.9\linewidth
%}

\newcommand{\ehref}[2]{\href{#1}{#2 \hspace{-.2em}{\scriptsize\faExternalLink}}}
%\newcommand{\eurl}[1]{\url{#1{\scriptsize \hspace{-.2em}\faExternalLink}}}
%%%

\usepgfplotslibrary{dateplot}

\usemintedstyle{trac}

\title{NICにおけるPCI Express性能の計測}
\subtitle{}
\date[\today]{}
%\author{Name (\ehref{http://twitter.com/twitter}{\faTwitter  twitter})}
\author{Yohei Kuga@KEIO Univ}
\institute{高速PCルータ研究会 2015/5}

\begin{document}

\maketitle

%% -------------------------------------------------- %%

\begin{frame}[fragile,t]{今日の話}
\begin{enumerate}
\item PCIe NICの基礎体力測定
\item ざっくばらんにFPGA開発ネタ
	\begin{itemize}
	\item FPGA+SystemVerilogで合成可能なパケット処理を考える
	\item その他のFPGA NIC実装
	\end{itemize}
\end{enumerate}
\end{frame}

%% -------------------------------------------------- %%

\begin{frame}[fragile,t]{Motivation}

ネットワークを高機能化するためにNICを自由に拡張したい
\vspace{.5em}

最近のDC+SW界隈 (Kernel bypass/Unikernels) に比べて，ネットワークHWはまだまだユーザ拡張性が低い
\vspace{-.5em}
\begin{itemize}
\item 現在のOffload機能はL2\~{}L4パケットヘッダ操作が主流
    \begin{itemize}
        \item Capsulation, CSUM, TCP など
    \end{itemize}
\item Programmable NICの検討は始まっている
\end{itemize}
\vspace{.5em}

"NICがProgrammableであること"が最初の一歩
\vspace{-.5em}
\begin{itemize}
\item ヘッダやFIB操作はProgrammable NICやNPUで実現可能
\item ペイロード操作/Interrupt/PCIe/遅延制御などを直接触りたいならFPGA NICが有力
\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile,t]{今回のチャレンジ}

前回: シングルポート1GE NIC
\vspace{-.5em}
\begin{itemize}
\item Lattice ECP3 versa kit (1GEx2 + PCIe1.1)
\item PCIE-TX: PIO write + Write combining, RX: DMA write
\item Linux Driver and Timestamp機能
\end{itemize}

\vspace{1em}

今回: マルチポート10GE NIC
\vspace{-.5em}
\begin{itemize}
\item KC705 (10GEx4 + PCIe gen2 x8) or NetFPGA-SUME
\item PCIE: TX: DMA read, RX: DMA write
\item 性能目標: 少なくとも10G 2ポートはline rate出したい
\end{itemize}

\end{frame}

%%%

\begin{frame}[fragile,t]{FPGA NICのどこらへんが難しいのか}

いまのところ \textbf{マルチポート} らへんが課題
\vspace{-.5em}
\begin{itemize}
\item Ethernetポートは増やせても使えるPCIe帯域は共通
\item だめ回路ではマルチポートで性能がだせない可能性がある
\end{itemize}

\vspace{.5em}

しかしマルチポートNICのPCIe利用帯域の見積もりは難しい
\vspace{-.5em}
\begin{itemize}
\item ネットワークではマルチポート送受信利用が前提だがPCIeは共有
\item マルチポートEthernet利用時のTLP送信待ち時間が課題
\item マルチポート40GE/100GE NICがきびしい理由を計測から考える
\end{itemize}

\textcolor{blue}{今回は，市販NICでPCIeの現実に使える利用可能帯域を計測}
%\item あと，ここ1,2年で使えう用になったsystemverilogがとてもよかったので，その話もあとで少しだけ

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile,t]{計測のねらい}

\begin{itemize}
\item Ethernetの性能を最大限出すために，現実的なPCIeの利用可能帯域を探りたい
\item 一方で，市販NICはPCIe帯域に余裕を持って設計されているため，計測方法に工夫が必要
\item 今回はIntel x520-SR2 (10GE x2)を用いて計測
\end{itemize}
\vspace{-1em}

\begin{table}
\small{Intel 82599: Host Interface Features\footnotemark}
\begin{tabular}{l|l}
	\toprule
	PCIe Host Interface &  PCIe gen2 (2.5GT/s, 5GT/s)\\
	Number of Lanes & x1, x2, x4, x8\\
	\bottomrule
\end{tabular}
\end{table}

意図的にNIC PCIeの使用レーン数を絞ることでThroughputを計測

\footnotetext[1]{\ehref{http://www.intel.com/content/dam/www/public/us/en/documents/datasheets/82599-10-gbe-controller-datasheet.pdf}{(PDF) Intel 82599 10 GbE Controller Datasheet}}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile,t]{計測環境}
\vspace{-1em}
\begin{table}
\begin{tabular}{l|l}
	\toprule
	Host CPU & Intel Core i7 4770\\
	NIC & Intel x520-SR2\\
	\midrule
	OS & BSD Router 1.55 (FreeBSD 10.1-RELEASE-p8)\\
	Tool & netmap pkt-gen\\
	\bottomrule
\end{tabular}
\end{table}

\vspace{-1em}
\begin{figure}
\includegraphics[width=.9\textwidth]{fig/test.pdf}
\end{figure}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{テープを使ってPCIeスロットを物理マスク}

\begin{figure}
\includegraphics[width=.9\textwidth]{pic/x1.png} \\
\includegraphics[width=.9\textwidth]{pic/x4.png}

\begin{scriptsize}
\begin{tcolorbox}[width=.9\linewidth]
\$ sudo lspci -vv\\
01:00.0 Ethernet controller: Intel Corporation 82599ES\\
LnkCap: Port \#0, \textbf{Speed 5GT/s, Width x8}, ... \\
LnkSta: \textbf{Speed 5GT/s, Width x1}, ...
\end{tcolorbox}
\end{scriptsize}
\vspace{-.5em}
\small{上: x1マスク, 中: x4マスク, 下: x1時のLink status}
\end{figure}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%


\begin{frame}[fragile,t]{計測環境}

\vspace{-1.5em}
\begin{figure}
\includegraphics[width=.9\textwidth]{fig/test2.pdf}
\end{figure}

\vspace{-1em}

計測結果の注意点
\vspace{-.5em}
\begin{itemize}
\item Softwareで試験パケットを生成しているので計測PPSに誤差が生じる
\item もちろんx8の時に最大限PCIe性能がだせる回路と考えられるので，NICそのものの絶対評価ではない
\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Max. TX Throughput}
	\begin{figure}
		\resizebox{.7\textwidth}{!}{\input{fig/pcie-lane-bps}}
	\end{figure}
	{\footnotesize Theoretical Max. Throughput (GT/s) * 8b/10b overhead (0.8): \\
	x1: 4Gbps, x2: 8Gbps, x4: 16Gbps, x8: 32Gbps}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{\% of Max. TX Throughput}
	\begin{figure}
		\resizebox{.7\textwidth}{!}{\input{fig/pcie-lane-ratio}}
	\end{figure}
	{\footnotesize Theoretical Max. Throughput (GT/s) * 8b/10b overhead (0.8): \\
	x1: 4Gbps, x2: 8Gbps, x4: 16Gbps, x8: 32Gbps}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile,t]{NICのPCIe基礎体力測定 考察}
	\vspace{-2em}
	\begin{figure}
		\resizebox{.8\textwidth}{!}{\input{fig/pcie-lane-ratio2}}
	\end{figure}
	\vspace{-1.5em}

	PCIe利用可能帯域を計測することでNIC回路の性能を推測
	\vspace{-.5em}
	\begin{itemize}
		\item 送信のみの場合，PCIeの約81\%の帯域が利用可能
		\item 送受信時，PCIeの約73\%の帯域が利用可能
		\item 送受信時，1514B-60Bで約20\%利用可能帯域が減少
		\item (PCIeはFull duplexにも関わらず) 60B送受信-送信のみ \\
		      で，PCIe利用可能帯域が約18\%減少
	\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile,t]{NICのPCIe基礎体力測定 考察}
	\vspace{-2em}
	\begin{figure}
		\resizebox{.8\textwidth}{!}{\input{fig/pcie-lane-ratio2}}
	\end{figure}
	\vspace{-1.5em}

	\begin{itemize}
		\item PCIeの最大利用可能帯域の割合で見るとx1, x2で同じ傾向
		\item x4(TXRX60B以外)とx8では，Ethernet帯域(10Gbps)を上回るので特性は見えない
	\end{itemize}

	\hspace{-0.5em}検討内容
	\vspace{-.5em}
	\begin{enumerate}
		\item パケットサイズとPCIe利用可能帯域の関係
		\item Full duplexとPCIe利用可能帯域の関係
	\end{enumerate}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile,t]{NICのおさらい}

\hspace{-0.5em}
\textcolor{blue}{パケット送信時のPCIe操作}
\vspace{-.5em}
\begin{enumerate}
	\item ドライバがNICのリングバッファのTail pointerを更新
	\item データ転送 (DMA read)
	\item Write-back the NIC status
\end{enumerate}

\hspace{-0.5em}
\textcolor{blue}{パケット受信時のPCIe操作}
\vspace{-.5em}
\begin{enumerate}
	\item データ転送 (DMA write)
	\item ドライバがTail pointerを更新
\end{enumerate}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile,t]{PCIeのおさらい}

\begin{itemize}
	\item PCIeのメモリ操作は送受信のレーンを使ってTLPパケットの通信が発生
	\item Ethernetポートを送受信パケットでFull duplex専有しても，PCIeでは上り下りリンクの専有ができるわけではない ⇛ TLPパケットの送信待ちが発生する
\end{itemize}

\hspace{-0.5em}
\textcolor{blue}{Ethernetパケット送信 (DMA read)}
\vspace{-.5em}
\begin{enumerate}
	\item TLP (Memory read)を送信
	\item ACKとデータ付きコンプリーションを受信
	\item コンプリーションに対するACKを送信
\end{enumerate}

\hspace{-0.5em}
\textcolor{blue}{Ethernetパケット受信時 (DMA write)}
\vspace{-.5em}
\begin{enumerate}
	\item TLP (Memory write)を送信
	\item ACKを受信
\end{enumerate}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile,t]{計測結果をどう考えるか}
	\vspace{-2em}
	\begin{figure}
		\resizebox{.8\textwidth}{!}{\input{fig/pcie-lane-ratio2}}
	\end{figure}
	\vspace{-2em}

	\begin{table}
	\small{参考データ}
	\begin{tabular}{l|l|l|l}
		\toprule
		  & Throughput & \%. gen3x8(64Gbps) & \%. gen3x16(128Gbps) \\
		\midrule
		10GE & 10Gbps & 15  & 8 \\
		40GE & 40Gbps & 62  & 31 \\
		100GE & 100Gbps & - & 78 \\
		\bottomrule
	\end{tabular}
	\end{table}

	\small{Xeon環境があるとPCMでもう少し詳細がわかりそう}

	\small{NICのレーン数の変更はEEPROMの書き換えで変更できるかも}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%

\plain{ざっくばらんにFPGA開発ネタ}

%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile,t]{FPGA開発環境の話}
\begin{itemize}
	\item Xilinx vivadoではSystemverilogで論理合成が可能になった
	\vspace{-0.7em}
	\begin{itemize}
		\item 使える型が増えた (typedef, union, struct, enum, etc) \\
		      ⇛ FPGA回路の合成時に型のチェックができるだけでもかなりうれしい
		\item Classなど合成できないSVの機能はまだまだ多い
		\item FPGAでのunionやenumはとても強力
		\item VHDL, Verilog混在環境で合成可能
	\end{itemize}
	\item Systemverilogがとても良かったので合成可能なパケット処理を考えてみる
	\begin{itemize}
		\item Classなどが使えないのでOSSで公開されているような検証用ライブラリはそのままでは使えない
		\item そこでLinuxのRaw socketぽくしてみる
	\end{itemize}
\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile,t]
  \frametitle{Systemverilogによるパケット処理 [1/3]}

\begin{figure}
\begin{tcolorbox}[title=ethernet\_pkg.sv]
\begin{minted}[fontsize=\small]{verilog}
/* MAC adderss */
typedef bit [ETH_ALEN-1:0][7:0] macaddr_t;

/* ethernet header */
typedef struct packed {
    macaddr_t h_dest;
    macaddr_t h_source;
    bit [15:0] h_proto;
} ethhdr;
\end{minted}
\end{tcolorbox}
\end{figure}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile,t]
  \frametitle{Systemverilogによるパケット処理 [2/3]}

\begin{figure}
\begin{tcolorbox}[title=user\_app.sv]
\begin{minted}[fontsize=\small]{verilog}
union packed {
    bit [5:0][63:0] raw;      // XGMII (64bit)
    struct packed {
        ethhdr eth;
        iphdr ip;
        udphdr udp;
        bit [47:0] padding;
    } hdr;
} tx_pkt, rx_pkt;
\end{minted}
\end{tcolorbox}
\end{figure}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{frame}[fragile,t]
  \frametitle{Systemverilogによるパケット処理 [3/3]}

\vspace{-1em}

\begin{figure}
\begin{tcolorbox}[title=TX]
\begin{minted}[fontsize=\small]{verilog}
// User register to XGMII_TX
xgmii.data = endian_conv64(tx_pkt.raw[5]);
\end{minted}
\end{tcolorbox}
%
\begin{tcolorbox}[title=RX]
\begin{minted}[fontsize=\small]{verilog}
// XGMII_RX to User register
rx_pkt.raw[5] <= endian_conv64(xgmii_rx.data);
...
// packet filtering
if (rx_pkt.hdr.eth.h_proto == ETH_P_IP &&
    rx_pkt.hdr.ip.protocol == IP4_PROTO_UDP &&
    rx_pkt.hdr.udp.dest    == 16'd9) begin
\end{minted}
\end{tcolorbox}
\end{figure}
%http://www.intel.com/content/dam/www/public/us/en/documents/datasheets/82599-10-gbe-controller-datasheet.pdf
\vspace{-.5em}
Raw socket ぽい?
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile,t]{その他のFPGA NIC実装}
\begin{itemize}
	\item NetFPGA-10G (最近1ポート10Gラインレート対応)
	\item NetFPGA-SUME (リファレンス回路待ち)
	\item KC705, VC709などのリファレンスNIC
\end{itemize}
それぞれ論理合成に2から3時間かかる\faMeh
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Summary}

\begin{itemize}
	\item 実験用のFPGA NIC回路を作るために，まずは市販NICのPCIe帯域を計測
	\begin{itemize}
		\item PCIeの使用レーンを減らすことでPCIe利用可能帯域を計測
		\item Ethert送受信時はPCIeの利用可能帯域が60\%前後まで下がった
		\item NICはEthernetの広帯域化に従って，PCIe利用可能帯域の効率化が課題になる
	\end{itemize}
	\item 100GE NIC以降はNIC間をデイジーチェーンでつないでPCIe帯域を増やすアプローチもあるらしい
	\item 今後は現在一般的なNICリングバッファ構造以外の方法を検討
\end{itemize}
\end{frame}

\plain{Questions? \faSmile}

\end{document}
